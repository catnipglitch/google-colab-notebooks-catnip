{"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/catnipglitch/google-colab-notebooks-catnip/blob/main/colab_sample/Get_started_copied.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"NtVOlmDSHmh4"},"source":["##### Copyright 2025 Google LLC."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9r9Ggw012g9c"},"outputs":[],"source":["# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"eVmFDcYOSNiV"},"source":["# Gemini API: Getting started with Gemini 2.0\n","\n","<a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Get_started.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" height=30/></a>"]},{"cell_type":"markdown","metadata":{"id":"TrWvVAIP3c1v"},"source":["新しい **[Google Gen AI SDK](https://github.com/googleapis/python-genai)** は、[Gemini Developer API](https://ai.google.dev/gemini-api/docs) および [Vertex AI 上の Gemini API](https://cloud.google.com/vertex-ai/generative-ai/docs/overview) を通じて [Gemini モデル](https://ai.google.dev/gemini-api/docs/models) への統一されたインターフェースを提供します。いくつかの例外を除き、どちらのプラットフォームでも同じコードが動作します。このノートブックでは Developer API を使用します。\n","\n","このノートブックでは、以下の内容を順に説明します：\n","\n","* Google GenAI SDK の[インストールとセットアップ](Get_started.ipynb#scrollTo=Mfk6YY3G5kqp)\n","* [テキスト](Get_started.ipynb#scrollTo=6TYNPrNvQ8ue)および[マルチモーダル](#scrollTo=yww-vrxmRiIy)プロンプト\n","* [トークン数のカウント](Get_started.ipynb#scrollTo=_9B8pb7tv_Cx)\n","* システムインストラクションの設定\n","* [セーフティフィルタ](Get_started.ipynb#scrollTo=HTAnYx_bbxPk)の設定\n","* [マルチターンチャット](Get_started.ipynb#scrollTo=HTAnYx_bbxPk)の開始\n","* [生成出力の制御](Get_started.ipynb#scrollTo=nyZMoM6tgnTA)\n","* [関数呼び出し](Get_started.ipynb#scrollTo=Rl-y9SZywD0s)の利用\n","* [コンテンツストリーム](Get_started.ipynb#scrollTo=uQfLCxfQtPTg)の生成と[非同期リクエスト](Get_started.ipynb#scrollTo=plCtEIaHuv96)の送信\n","* [ファイルアップロード](Get_started.ipynb#scrollTo=enBhuaIk3KYa)の利用\n","* [コンテキストキャッシュ](Get_started.ipynb#scrollTo=oTgeR3_9wN5J)の利用\n","* [テキスト埋め込み](Get_started.ipynb#scrollTo=sXNCRn8Wx71d)の生成\n","\n","この新しい SDK の詳細は[ドキュメント](https://ai.google.dev/gemini-api/docs/sdks)をご覧ください。"]},{"cell_type":"markdown","metadata":{"id":"Mfk6YY3G5kqp"},"source":["## Setup"]},{"cell_type":"markdown","metadata":{"id":"d5027929de8f"},"source":["### Install SDK\n","\n","[PyPI](https://github.com/googleapis/python-genai) から SDK をインストールします。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"46zEFO2a9FFd"},"outputs":[],"source":["%pip install -U -q 'google-genai>=1.4.0' # 1.4.0 is needed for chat history"]},{"cell_type":"markdown","metadata":{"id":"CTIfnvCn9HvH"},"source":["### Setup your API key\n","\n","以下のセルを実行するには、API キーを Colab Secret の `GOOGLE_API_KEY` に保存しておく必要があります。API キーをまだ持っていない場合や Colab Secret の作成方法が分からない場合は、[認証方法](../quickstarts/Authentication.ipynb)の例を参照してください。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A1pkoyZb9Jm3"},"outputs":[],"source":["from google.colab import userdata\n","\n","GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')"]},{"cell_type":"markdown","metadata":{"id":"3Hx_Gw9i0Yuv"},"source":["### Initialize SDK client\n","\n","新しい SDK では、API キー（または [Vertex AI](https://cloud.google.com/vertex-ai) を利用する場合は OAuth）でクライアントを初期化するだけで済みます。モデルは各呼び出しごとに指定します。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HghvVpbU0Uap"},"outputs":[],"source":["from google import genai\n","from google.genai import types\n","\n","client = genai.Client(api_key=GOOGLE_API_KEY)"]},{"cell_type":"markdown","metadata":{"id":"MvA_mbi1JxD5"},"source":["### Choose a model\n","\n","このガイドで使用するモデルを選択してください。リストから選択するか、モデル名を手動で入力できます。2.5系のモデルなど一部は「thinking model」となっており、応答にやや時間がかかる場合があります。詳細は [thinking notebook](./Get_started_thinking.ipynb) を参照してください。\n","\n","すべての Gemini モデルの概要は[ドキュメント](https://ai.google.dev/gemini-api/docs/models/gemini)をご覧ください。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AChpZWIXu62m"},"outputs":[],"source":["MODEL_ID = \"gemini-2.5-flash-preview-04-17\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}"]},{"cell_type":"markdown","metadata":{"id":"6TYNPrNvQ8ue"},"source":["## Send text prompts\n","\n","`generate_content` メソッドを使ってプロンプトへの応答を生成します。テキストを直接 `generate_content` に渡し、`.text` プロパティで応答のテキスト内容を取得できます。出力が1つのパートのみの場合、`.text` フィールドが利用できます。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T8md0ayAJ-RZ"},"outputs":[],"source":["from IPython.display import Markdown\n","\n","response = client.models.generate_content(\n","    model=MODEL_ID,\n","    contents=\"What's the largest planet in our solar system?\"\n",")\n","\n","Markdown(response.text)"]},{"cell_type":"markdown","metadata":{"id":"_9B8pb7tv_Cx"},"source":["## Count tokens\n","\n","トークンは Gemini モデルへの基本的な入力単位です。`count_tokens` メソッドを使うと、Gemini API にリクエストを送る前に入力トークン数を計算できます。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z7WFm928wEYR"},"outputs":[],"source":["response = client.models.count_tokens(\n","    model=MODEL_ID,\n","    contents=\"What's the highest mountain in Africa?\",\n",")\n","\n","print(response)"]},{"cell_type":"markdown","metadata":{"id":"yww-vrxmRiIy"},"source":["## Send multimodal prompts\n","\n","Gemini 2.0 モデル（`gemini-2.0-flash-exp`）はマルチモーダルプロンプトをサポートしています。テキスト、[PDF ドキュメント](../quickstarts/PDF_Files.ipynb)、画像、[音声](../quickstarts/Audio.ipynb)、[動画](../quickstarts/Video.ipynb)をプロンプトに含めて、テキストやコードの応答を得ることができます。\n","\n","最初の例では、指定した URL から画像をダウンロードし、バイトストリームとして保存し、そのバイトをローカルファイル `jetpack.png` に書き込みます。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bQ3zu5udSBuD"},"outputs":[],"source":["import requests\n","import pathlib\n","from PIL import Image\n","\n","IMG = \"https://storage.googleapis.com/generativeai-downloads/data/jetpack.png\" # @param {type: \"string\"}\n","\n","img_bytes = requests.get(IMG).content\n","\n","img_path = pathlib.Path('jetpack.png')\n","img_path.write_bytes(img_bytes)"]},{"cell_type":"markdown","metadata":{"id":"xSjAMbVjOlnc"},"source":["In this second example, you'll open a previously saved image, create a thumbnail of it and then generate a short blog post based on the thumbnail, displaying both the thumbnail and the generated blog post."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cDxd7Pp_SELb"},"outputs":[],"source":["from IPython.display import display, Markdown\n","image = Image.open(img_path)\n","image.thumbnail([512,512])\n","\n","response = client.models.generate_content(\n","    model=MODEL_ID,\n","    contents=[\n","        image,\n","        \"Write a short and engaging blog post based on this picture.\"\n","    ]\n",")\n","\n","display(image)\n","Markdown(response.text)"]},{"cell_type":"markdown","metadata":{"id":"VTzuBfHyWAg5"},"source":["## Configure model parameters\n","\n","各モデル呼び出し時にパラメータ値を指定して、応答の生成方法を制御できます。[パラメータ値の調整方法](https://ai.google.dev/gemini-api/docs/text-generation?lang=node#configure)の詳細も参照してください。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r5izy6jsbEnL"},"outputs":[],"source":["response = client.models.generate_content(\n","    model=MODEL_ID,\n","    contents=\"Tell me how the internet works, but pretend I'm a puppy who only understands squeaky toys.\",\n","    config=types.GenerateContentConfig(\n","        temperature=0.4,\n","        top_p=0.95,\n","        top_k=20,\n","        candidate_count=1,\n","        seed=5,\n","        max_output_tokens=100,\n","        stop_sequences=[\"STOP!\"],\n","        presence_penalty=0.0,\n","        frequency_penalty=0.0,\n","    )\n",")\n","\n","print(response.text)"]},{"cell_type":"markdown","metadata":{"id":"HTAnYx_bbxPk"},"source":["## Configure safety filters\n","\n","Gemini API では複数のカテゴリでセーフティフィルタを調整でき、特定の種類のコンテンツを制限または許可できます。これらのフィルタを使って、用途に応じた適切な出力を得ることができます。詳細は[セーフティフィルタの設定](https://ai.google.dev/gemini-api/docs/safety-settings)ページを参照してください。\n","\n","この例では、危険度の高いコンテンツのみをブロックするセーフティフィルタを使い、失礼なフレーズの生成をリクエストします。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SJIvAfMqbzQL"},"outputs":[],"source":["prompt = \"\"\"\n","    Write a list of 2 disrespectful things that I might say to the universe after stubbing my toe in the dark.\n","\"\"\"\n","\n","safety_settings = [\n","    types.SafetySetting(\n","        category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n","        threshold=\"BLOCK_ONLY_HIGH\",\n","    ),\n","]\n","\n","response = client.models.generate_content(\n","    model=MODEL_ID,\n","    contents=prompt,\n","    config=types.GenerateContentConfig(\n","        safety_settings=safety_settings,\n","    ),\n",")\n","\n","Markdown(response.text)"]},{"cell_type":"markdown","metadata":{"id":"b6sB7W-jdGxJ"},"source":["## Start a multi-turn chat\n","\n","Gemini API では、複数ターンにわたる自由な会話が可能です。\n","\n","次に、役立つコーディングアシスタントをセットアップします："]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mIC0pLnJdI8m"},"outputs":[],"source":["system_instruction = \"\"\"\n","  You are an expert software developer and a helpful coding assistant.\n","  You are able to generate high-quality code in any programming language.\n","\"\"\"\n","\n","chat_config = types.GenerateContentConfig(\n","    system_instruction=system_instruction,\n",")\n","\n","chat = client.chats.create(\n","    model=MODEL_ID,\n","    config=chat_config,\n",")"]},{"cell_type":"markdown","metadata":{"id":"KVQZitGE7EbW"},"source":["Use `chat.send_message` to pass a message back and receive a response."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SnzMJJ-adOfX"},"outputs":[],"source":["response = chat.send_message(\"Write a function that checks if a year is a leap year.\")\n","\n","Markdown(response.text)"]},{"cell_type":"markdown","metadata":{"id":"gWWcDneQO4Ya"},"source":["Here's another example using your new helpful coding assistant:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9qAObeZMdgln"},"outputs":[],"source":["response = chat.send_message(\"Okay, write a unit test of the generated function.\")\n","\n","Markdown(response.text)"]},{"cell_type":"markdown","metadata":{"id":"FNX4AQ9AWddm"},"source":["## Save and resume a chat\n","\n","Python SDK のほとんどのオブジェクトは [Pydantic モデル](https://docs.pydantic.dev/latest/concepts/models/)として実装されています。Pydantic にはオブジェクトのシリアライズやデシリアライズの機能があるため、永続化に利用できます。\n","\n","この例では、[`Chat`](https://googleapis.github.io/python-genai/genai.html#genai.chats.Chat) セッションを JSON で保存・復元する方法を示します。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zuoSfLW5Xl1V"},"outputs":[],"source":["from pydantic import TypeAdapter\n","\n","# Chat history is a list of Content objects. A TypeAdapter can convert to and from\n","# these Pydantic types.\n","history_adapter = TypeAdapter(list[types.Content])\n","\n","# Use the chat object from the previous section.\n","chat_history = chat.get_history()\n","\n","# Convert to a JSON list.\n","json_history = history_adapter.dump_json(chat_history)"]},{"cell_type":"markdown","metadata":{"id":"E4xU6wpPZRdL"},"source":["At this point you can save the JSON bytestring to disk or wherever you persist data. When you load it again, you can instantiate a new chat session using the stored history."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hq1bAsX8ZRS3"},"outputs":[],"source":["# Convert the JSON back to the Pydantic schema.\n","history = history_adapter.validate_json(json_history)\n","\n","# Now load a new chat session using the JSON history.\n","new_chat = client.chats.create(\n","    model=MODEL_ID,\n","    config=chat_config,\n","    history=history,\n",")\n","\n","response = new_chat.send_message(\"What was the name of the function again?\")\n","Markdown(response.text)"]},{"cell_type":"markdown","metadata":{"id":"nyZMoM6tgnTA"},"source":["## Generate JSON\n","\n","Gemini API の [controlled generation](https://ai.google.dev/gemini-api/docs/structured-output?lang=python#generate-json) 機能を使うと、モデルの出力を構造化フォーマットに制約できます。Pydantic モデルや JSON 文字列でスキーマを指定できます。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xRJHVjr-gqHi"},"outputs":[],"source":["from pydantic import BaseModel\n","import json\n","\n","class Recipe(BaseModel):\n","    recipe_name: str\n","    recipe_description: str\n","    recipe_ingredients: list[str]\n","\n","response = client.models.generate_content(\n","    model=MODEL_ID,\n","    contents=\"Provide a popular cookie recipe and its ingredients.\",\n","    config=types.GenerateContentConfig(\n","        response_mime_type=\"application/json\",\n","        response_schema=Recipe,\n","    ),\n",")\n","\n","print(json.dumps(json.loads(response.text), indent=4))"]},{"cell_type":"markdown","metadata":{"id":"cHLitKXj1hZa"},"source":["## Generate Images\n","\n","Gemini は会話の一部として画像を直接出力できます："]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qbdnNzGL6R_2"},"outputs":[],"source":["from IPython.display import Image, Markdown\n","\n","response = client.models.generate_content(\n","    model=\"gemini-2.0-flash-exp\",\n","    contents='Hi, can create a 3d rendered image of a pig with wings and a top hat flying over a happy futuristic scifi city with lots of greenery?',\n","    config=types.GenerateContentConfig(\n","        response_modalities=['Text', 'Image']\n","    )\n",")\n","\n","for part in response.candidates[0].content.parts:\n","  if part.text is not None:\n","    display(Markdown(part.text))\n","  elif part.inline_data is not None:\n","    mime = part.inline_data.mime_type\n","    print(mime)\n","    data = part.inline_data.data\n","    display(Image(data=data))"]},{"cell_type":"markdown","metadata":{"id":"Q1tAq1kSxgoY"},"source":["[Imagen](./Get_started_imagen.ipynb) も画像生成の別の方法です。用途ごとの推奨は[ドキュメント](https://ai.google.dev/gemini-api/docs/image-generation#choose-a-model)を参照してください。"]},{"cell_type":"markdown","metadata":{"id":"uQfLCxfQtPTg"},"source":["## Generate content stream\n","\n","デフォルトでは、モデルは生成処理が完了してから応答を返します。`generate_content_stream` メソッドを使うと、生成中の応答をストリームとして受け取ることができ、生成された部分から順次返されます。\n","\n","thinking model を使っている場合、思考処理が終わってからストリーミングが始まる点に注意してください。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3gIsSNqXtOXB"},"outputs":[],"source":["for chunk in client.models.generate_content_stream(\n","    model=MODEL_ID,\n","    contents=\"Tell me a story about a lonely robot who finds friendship in a most unexpected place.\"\n","):\n","  print(chunk.text)\n","  print(\"*****************\")"]},{"cell_type":"markdown","metadata":{"id":"plCtEIaHuv96"},"source":["## Send asynchronous requests\n","\n","`client.aio` では、`client` で利用できるすべての非同期メソッドが提供されています。\n","\n","たとえば、`client.aio.models.generate_content` は `client.models.generate_content` の非同期版です。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OPTI7noYuwgr"},"outputs":[],"source":["response = await client.aio.models.generate_content(\n","    model=MODEL_ID,\n","    contents=\"Compose a song about the adventures of a time-traveling squirrel.\"\n",")\n","\n","Markdown(response.text)"]},{"cell_type":"markdown","metadata":{"id":"Rl-y9SZywD0s"},"source":["## Function calling\n","\n","[Function calling](https://ai.google.dev/gemini-api/docs/function-calling) を使うと、モデルがユーザーのプロンプトに応じて利用できるツール群を提供できます。コード内で関数の説明を作成し、その説明をリクエストで言語モデルに渡します。モデルの応答には次が含まれます：\n","- 説明に合致する関数名\n","- 呼び出しに使う引数"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"APk6sXO6wLQp"},"outputs":[],"source":["get_destination = types.FunctionDeclaration(\n","    name=\"get_destination\",\n","    description=\"Get the destination that the user wants to go to\",\n","    parameters={\n","        \"type\": \"OBJECT\",\n","        \"properties\": {\n","            \"destination\": {\n","                \"type\": \"STRING\",\n","                \"description\": \"Destination that the user wants to go to\",\n","            },\n","        },\n","    },\n",")\n","\n","destination_tool = types.Tool(\n","    function_declarations=[get_destination],\n",")\n","\n","response = client.models.generate_content(\n","    model=MODEL_ID,\n","    contents=\"I'd like to travel to Paris.\",\n","    config=types.GenerateContentConfig(\n","        tools=[destination_tool],\n","        temperature=0,\n","        ),\n",")\n","\n","response.candidates[0].content.parts[0].function_call"]},{"cell_type":"markdown","metadata":{"id":"NsNd3DtDFX1X"},"source":["## Code execution\n","\n","[Code execution](https://ai.google.dev/gemini-api/docs/code-execution?lang=python) を使うと、モデルが複雑な質問に答えるための Python コードを生成・実行できます。詳細な例は [Code execution クイックスタートガイド](./Code_execution.ipynb) を参照してください。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fY062-nsGLBu"},"outputs":[],"source":["from IPython.display import Image, Markdown, Code, HTML\n","\n","response = client.models.generate_content(\n","    model=MODEL_ID,\n","    contents=\"Generate and run a script to count how many letter r there are in the word strawberry\",\n","    config = types.GenerateContentConfig(\n","        tools=[types.Tool(code_execution=types.ToolCodeExecution)]\n","    )\n",")\n","\n","for part in response.candidates[0].content.parts:\n","  if part.text is not None:\n","    display(Markdown(part.text))\n","  if part.executable_code is not None:\n","    code_html = f'<pre style=\"background-color: green;\">{part.executable_code.code}</pre>'\n","    display(HTML(code_html))\n","  if part.code_execution_result is not None:\n","    display(Markdown(part.code_execution_result.output))\n","  if part.inline_data is not None:\n","    display(Image(data=part.inline_data.data, format=\"png\"))\n","  display(Markdown(\"---\"))"]},{"cell_type":"markdown","metadata":{"id":"enBhuaIk3KYa"},"source":["## Upload files\n","\n","マルチモーダルプロンプトの送信方法を学んだので、さまざまなマルチメディアタイプのファイルを API にアップロードしてみましょう。前述のマルチモーダル例のような小さな画像の場合は、プロンプトで Gemini モデルにローカルファイルを直接指定できます。大きなファイルや複数ファイル、何度も送信したくないファイルは File Upload API を使い、参照で渡します。\n","\n","大きなテキストファイル、画像、動画、音声の場合は、プロンプトに含める前に File API でアップロードしてください。"]},{"cell_type":"markdown","metadata":{"id":"zGswPFKrTvby"},"source":["### Upload an image file\n","\n","この例を実行すると、\"jetpack.png\" 画像のローカルコピーが Python スクリプトの実行ディレクトリに保存されます。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8FVVJHb828le"},"outputs":[],"source":["# Prepare the file to be uploaded\n","IMG = \"https://storage.googleapis.com/generativeai-downloads/data/jetpack.png\"  # @param {type: \"string\"}\n","img_bytes = requests.get(IMG).content\n","\n","img_path = pathlib.Path('jetpack.png')\n","img_path.write_bytes(img_bytes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NlJ9NwRGT6d1"},"outputs":[],"source":["# Upload the file using the API\n","file_upload = client.files.upload(file=img_path)\n","\n","response = client.models.generate_content(\n","    model=MODEL_ID,\n","    contents=[\n","        file_upload,\n","        \"Write a short and engaging blog post based on this picture.\",\n","    ]\n",")\n","\n","Markdown(response.text)"]},{"cell_type":"markdown","metadata":{"id":"D1y5eZmqThDR"},"source":["### Upload text file\n","\n","まずはテキストファイルをアップロードします。この例では [Apollo 11](https://www.nasa.gov/history/alsj/a11/a11trans.html) の400ページのトランスクリプトを使用します。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Sa6lEH9Tjm5"},"outputs":[],"source":["# Prepare the file to be uploaded\n","TEXT = \"https://storage.googleapis.com/generativeai-downloads/data/a11.txt\"  # @param {type: \"string\"}\n","text_bytes = requests.get(TEXT).content\n","\n","text_path = pathlib.Path('a11.txt')\n","text_path.write_bytes(text_bytes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kC3bJQJcUKFk"},"outputs":[],"source":["# Upload the file using the API\n","file_upload = client.files.upload(file=text_path)\n","\n","response = client.models.generate_content(\n","    model=MODEL_ID,\n","    contents=[\n","        file_upload,\n","        \"Can you give me a summary of this information please?\",\n","    ]\n",")\n","\n","Markdown(response.text)"]},{"cell_type":"markdown","metadata":{"id":"QLV19RrMUlaw"},"source":["### Upload a PDF file\n","\n","この PDF ページは、Google Research Blog で公開されている [Smoothly editing material properties of objects](https://research.google/blog/smoothly-editing-material-properties-of-objects-with-text-to-image-models-and-synthetic-data/) という記事です。\n","\n","まず、URL から PDF ファイルをダウンロードし、ローカルに \"article.pdf\" として保存します。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b0BfhLDFWfCS"},"outputs":[],"source":["# Prepare the file to be uploaded\n","PDF = \"https://storage.googleapis.com/generativeai-downloads/data/Smoothly%20editing%20material%20properties%20of%20objects%20with%20text-to-image%20models%20and%20synthetic%20data.pdf\"  # @param {type: \"string\"}\n","pdf_bytes = requests.get(PDF).content\n","\n","pdf_path = pathlib.Path('article.pdf')\n","pdf_path.write_bytes(pdf_bytes)"]},{"cell_type":"markdown","metadata":{"id":"bjrfdaiYPuIL"},"source":["Secondly, you'll upload the saved PDF file and generate a bulleted list summary of its contents."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tH2h2WDVWptt"},"outputs":[],"source":["# Upload the file using the API\n","file_upload = client.files.upload(file=pdf_path)\n","\n","response = client.models.generate_content(\n","    model=MODEL_ID,\n","    contents=[\n","        file_upload,\n","        \"Can you summarize this file as a bulleted list?\",\n","    ]\n",")\n","\n","Markdown(response.text)"]},{"cell_type":"markdown","metadata":{"id":"9NWO1moe9fx-"},"source":["### Upload an audio file\n","\n","この例では、ジョン・F・ケネディ大統領の1961年一般教書演説の[録音](https://www.jfklibrary.org/asset-viewer/archives/jfkwha-006)を使用します。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lCSuGd9i9fEB"},"outputs":[],"source":["# Prepare the file to be uploaded\n","AUDIO = \"https://storage.googleapis.com/generativeai-downloads/data/State_of_the_Union_Address_30_January_1961.mp3\"  # @param {type: \"string\"}\n","audio_bytes = requests.get(AUDIO).content\n","\n","audio_path = pathlib.Path('audio.mp3')\n","audio_path.write_bytes(audio_bytes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0wjKO0eI9yps"},"outputs":[],"source":["# Upload the file using the API\n","file_upload = client.files.upload(file=audio_path)\n","\n","response = client.models.generate_content(\n","    model=MODEL_ID,\n","    contents=[\n","        file_upload,\n","        \"Listen carefully to the following audio file. Provide a brief summary\",\n","    ]\n",")\n","\n","Markdown(response.text)"]},{"cell_type":"markdown","metadata":{"id":"KdUjkIQP-G_i"},"source":["### Upload a video file\n","\n","この例では、[Big Buck Bunny](https://peach.blender.org/about/) の短いクリップを使用します。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e9ohtLxU-SFE"},"outputs":[],"source":["# Download the video file\n","VIDEO_URL = \"https://download.blender.org/peach/bigbuckbunny_movies/BigBuckBunny_320x180.mp4\"  # @param {type: \"string\"}\n","video_file_name = \"BigBuckBunny_320x180.mp4\"\n","!wget -O {video_file_name} $VIDEO_URL"]},{"cell_type":"markdown","metadata":{"id":"iyFVXPspS5GF"},"source":["Let's start by uploading the video file."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PY1WlxMk-0Uy"},"outputs":[],"source":["# Upload the file using the API\n","video_file = client.files.upload(file=video_file_name)\n","print(f\"Completed upload: {video_file.uri}\")"]},{"cell_type":"markdown","metadata":{"id":"_yRG9BPXS65b"},"source":["> **Note:** 動画の状態が重要です。動画の処理が完了するまで状態を確認してください。動画の状態が `ACTIVE` になったら `generate_content` に渡せます。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eEk4P3fK_OcJ"},"outputs":[],"source":["import time\n","\n","# Check the file processing state\n","while video_file.state == \"PROCESSING\":\n","    print('Waiting for video to be processed.')\n","    time.sleep(10)\n","    video_file = client.files.get(name=video_file.name)\n","\n","if video_file.state == \"FAILED\":\n","  raise ValueError(video_file.state)\n","print(f'Video processing complete: ' + video_file.uri)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oMz9GIuvAiCO"},"outputs":[],"source":["print(video_file.state)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cX82TyGL-e2O"},"outputs":[],"source":["# Ask Gemini about the video\n","response = client.models.generate_content(\n","    model=MODEL_ID,\n","    contents=[\n","        video_file,\n","        \"Describe this video.\",\n","    ]\n",")\n","\n","Markdown(response.text)"]},{"cell_type":"markdown","metadata":{"id":"65_qu3UsM8_M"},"source":["### Process a YouTube link"]},{"cell_type":"markdown","metadata":{"id":"GXNlrAsZR7bB"},"source":["For YouTube links, you don't need to explicitly upload the video file content, but you do need to explicitly declare the video URL you want the model to process as part of the `contents` of the request. For more information see the [vision](https://ai.google.dev/gemini-api/docs/vision?lang=python#youtube) documentation including the features and limits.\n","\n","> **Note:** You're only able to submit up to one YouTube link per `generate_content` request.\n","\n","> **Note:** If your text input includes YouTube links, the system won't process them, which may result in incorrect responses. To ensure proper handling, explicitly provide the URL using the `file_uri` parameter in `FileData`.\n","\n","The following example shows how you can use the model to summarize the video. In this case use a summary video of [Google I/O 2024](\"https://www.youtube.com/watch?v=WsEQjeZoEng\")."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zcqXUrYSTrLQ"},"outputs":[],"source":["response = client.models.generate_content(\n","    model=MODEL_ID,\n","    contents= types.Content(\n","        parts=[\n","            types.Part(text=\"Summarize this video.\"),\n","            types.Part(\n","                file_data=types.FileData(file_uri='https://www.youtube.com/watch?v=WsEQjeZoEng')\n","            )\n","        ]\n","    )\n",")\n","\n","Markdown(response.text)"]},{"cell_type":"markdown","metadata":{"id":"oTgeR3_9wN5J"},"source":["## Use context caching\n","\n","[Context caching](https://ai.google.dev/gemini-api/docs/caching?lang=python) を使うと、頻繁に使う入力トークンを専用キャッシュに保存し、以降のリクエストで参照できます。これにより、同じトークンセットを何度もモデルに渡す必要がなくなります。\n","\n","コンテキストキャッシュは、固定バージョンの安定モデル（例：`gemini-1.5-flash-002`）でのみ利用できます。バージョンのポストフィックス（例：`-002`）を必ず含めてください。より多くのキャッシュ例は[こちら](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Caching.ipynb)を参照してください。"]},{"cell_type":"markdown","metadata":{"id":"Tgl2gzmuwQXz"},"source":["#### Create a cache"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b2Jb0gaiwOVi"},"outputs":[],"source":["system_instruction = \"\"\"\n","  You are an expert researcher who has years of experience in conducting systematic literature surveys and meta-analyses of different topics.\n","  You pride yourself on incredible accuracy and attention to detail. You always stick to the facts in the sources provided, and never make up new facts.\n","  Now look at the research paper below, and answer the following questions in 1-2 sentences.\n","\"\"\"\n","\n","urls = [\n","    'https://storage.googleapis.com/cloud-samples-data/generative-ai/pdf/2312.11805v3.pdf',\n","    \"https://storage.googleapis.com/cloud-samples-data/generative-ai/pdf/2403.05530.pdf\",\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZrZ64o5Sydm_"},"outputs":[],"source":["# Download files\n","pdf_bytes = requests.get(urls[0]).content\n","pdf_path = pathlib.Path('2312.11805v3.pdf')\n","pdf_path.write_bytes(pdf_bytes)\n","\n","pdf_bytes = requests.get(urls[1]).content\n","pdf_path = pathlib.Path('2403.05530.pdf')\n","pdf_path.write_bytes(pdf_bytes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZrylX7r3w2bF"},"outputs":[],"source":["# Upload the PDFs using the File API\n","uploaded_pdfs = []\n","uploaded_pdfs.append(client.files.upload(file='2312.11805v3.pdf'))\n","uploaded_pdfs.append(client.files.upload(file='2403.05530.pdf'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7MBsaipow7m5"},"outputs":[],"source":["# Create a cache with a 60 minute TTL\n","cached_content = client.caches.create(\n","    model=MODEL_ID,\n","    config=types.CreateCachedContentConfig(\n","      display_name='research papers', # used to identify the cache\n","      system_instruction=system_instruction,\n","      contents=uploaded_pdfs,\n","      ttl=\"3600s\",\n","  )\n",")\n","\n","cached_content"]},{"cell_type":"markdown","metadata":{"id":"2870527e1c84"},"source":["#### Listing available cache objects"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3be7c2339be3"},"outputs":[],"source":["for cache in client.caches.list():\n","  print(cache)"]},{"cell_type":"markdown","metadata":{"id":"KKgCRRXfwU_m"},"source":["#### Use a cache"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Qo7-sU2w92j"},"outputs":[],"source":["response = client.models.generate_content(\n","  model=MODEL_ID,\n","  contents=\"What is the research goal shared by these research papers?\",\n","  config=types.GenerateContentConfig(cached_content=cached_content.name)\n",")\n","\n","Markdown(response.text)"]},{"cell_type":"markdown","metadata":{"id":"4QSOsWurx4CG"},"source":["#### Delete a cache"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zSZeG60Dx4V-"},"outputs":[],"source":["result = client.caches.delete(name=cached_content.name)"]},{"cell_type":"markdown","metadata":{"id":"sXNCRn8Wx71d"},"source":["## Get text embeddings\n","\n","`embed_content` メソッドと `gemini-embedding-exp-03-07` モデルを使って、テキストの埋め込みを取得できます。\n","\n","Gemini Embeddings モデルはデフォルトで3072次元の出力を生成しますが、1～3072の範囲で出力次元数を選択できます。詳細は[埋め込みガイド](https://ai.google.dev/gemini-api/docs/embeddings)を参照してください。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hpJIA5zmx8Vy"},"outputs":[],"source":["TEXT_EMBEDDING_MODEL_ID = \"gemini-embedding-exp-03-07\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0afi69R9x_bh"},"outputs":[],"source":["response = client.models.embed_content(\n","    model=TEXT_EMBEDDING_MODEL_ID,\n","    contents=[\n","        \"How do I get a driver's license/learner's permit?\",\n","        \"How do I renew my driver's license?\",\n","        \"How do I change my address on my driver's license?\"\n","        ],\n","    config=types.EmbedContentConfig(output_dimensionality=512)\n",")\n","\n","print(response.embeddings)"]},{"cell_type":"markdown","metadata":{"id":"Tje8pMbd5z7j"},"source":["You'll get a set of three embeddings, one for each piece of text you passed in:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zNeuBlNt4CRk"},"outputs":[],"source":["len(response.embeddings)"]},{"cell_type":"markdown","metadata":{"id":"hG5UPmq3543E"},"source":["You can also see the length of each embedding is 512, as per the `output_dimensionality` you specified."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s4oAtC8a4GYH"},"outputs":[],"source":["print(len(response.embeddings[0].values))\n","print((response.embeddings[0].values[:4], '...'))"]},{"cell_type":"markdown","metadata":{"id":"_SOkIVJIyF1W"},"source":["## Next Steps\n","\n","### Useful API references:\n","\n","新しい SDK の詳細は [Google GenAI SDK](https://github.com/googleapis/python-genai) をご覧ください。\n","\n","### Related examples\n","\n","Gemini 2.0 のより詳細な例は [cookbook の Gemini 2.0 フォルダ](https://github.com/google-gemini/cookbook/tree/main/gemini-2/) を参照してください。[Live API](./Get_started_LiveAPI.ipynb) の使い方、[複数ツールの活用例](../examples/LiveAPI_plotting_and_mapping.ipynb)、Gemini 2.0 の[空間理解](./Spatial_understanding.ipynb)機能なども学べます。\n","\n","また、思考過程を明示的に示し、より複雑な推論ができる [experimental Gemini 2.0 Flash Thinking](./Get_started_thinking.ipynb) モデルもご覧ください。"]}],"metadata":{"colab":{"collapsed_sections":["Mfk6YY3G5kqp"],"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}